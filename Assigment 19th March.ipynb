{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51fcb72b-e4ff-41a9-88e6-bd9d2e427912",
   "metadata": {},
   "source": [
    "Q1. What is Min-Max scaling, and how is it used in data preprocessing? Provide an example to illustrate its\n",
    "application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6510ccb0-8af8-4cfb-a922-0322f6f5919d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.   0.  ]\n",
      " [0.25 0.25]\n",
      " [0.5  0.5 ]\n",
      " [0.75 0.75]\n",
      " [1.   1.  ]]\n"
     ]
    }
   ],
   "source": [
    "#Min-Max scaling, also known as feature scaling or normalization, is a common technique used in data preprocessing to\n",
    "#transform the values of numerical features into a range between 0 and 1. The formula for Min-Max scaling is:\n",
    "#X_scaled = (X - X_min) / (X_max - X_min)\n",
    "#where X is an original feature value, X_min and X_max are the minimum and maximum values of the feature in the dataset, \n",
    "#and X_scaled is the transformed value of X.\n",
    "\n",
    "#Min-Max scaling can be useful in many machine learning algorithms because it can improve the performance and accuracy of the model, \n",
    "#especially for algorithms that rely on distance measures or gradient descent optimization. It can also help to mitigate the effects\n",
    "#of different scales of features, which can otherwise cause some features to dominate others in the analysis.\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# create a sample dataset with two features\n",
    "data = {'age': [25, 30, 35, 40, 45],\n",
    "        'income': [50000, 60000, 70000, 80000, 90000]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# fit and transform the data\n",
    "df_scaled = scaler.fit_transform(df)\n",
    "\n",
    "# print the scaled data\n",
    "print(df_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5620691-8bc8-43ca-8c7a-c8af6ed0c1b9",
   "metadata": {},
   "source": [
    "Q2. What is the Unit Vector technique in feature scaling, and how does it differ from Min-Max scaling?\n",
    "\n",
    "Provide an example to illustrate its application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da211856-2e4f-4edc-9774-17c37e033945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.99999938e-04 9.99999875e-01]\n",
      " [4.99999938e-04 9.99999875e-01]\n",
      " [4.99999938e-04 9.99999875e-01]\n",
      " [4.99999938e-04 9.99999875e-01]\n",
      " [4.99999938e-04 9.99999875e-01]]\n"
     ]
    }
   ],
   "source": [
    "#The Unit Vector technique in feature scaling, also known as unit normalization, is another method used in data preprocessing to \n",
    "#transform the values of numerical features. Unlike Min-Max scaling, which transforms the values to a range between 0 and 1,\n",
    "#the Unit Vector technique transforms the values to have a magnitude of 1. The formula for Unit Vector scaling is:\n",
    "#X_scaled = X / ||X||\n",
    "#where X is an original feature value, ||X|| is the magnitude of the feature vector, and X_scaled is the transformed value of X.\n",
    "\n",
    "#Unit Vector scaling can be useful in many machine learning algorithms because it can help to normalize the scale of features that have\n",
    "#very different ranges or units of measurement. This can help to ensure that each feature contributes equally to the analysis and \n",
    "#can help to avoid issues with numerical instability or sensitivity to feature scaling.\n",
    "\n",
    "#Here's an example of how to use Unit Vector scaling in Python:\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "# create a sample dataset with two features\n",
    "data = {'age': [25, 30, 35, 40, 45],\n",
    "        'income': [50000, 60000, 70000, 80000, 90000]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# initialize the Normalizer\n",
    "scaler = Normalizer()\n",
    "\n",
    "# fit and transform the data\n",
    "df_scaled = scaler.fit_transform(df)\n",
    "\n",
    "# print the scaled data\n",
    "print(df_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff86ec49-de3a-46d6-ab8c-ea3b5b70d792",
   "metadata": {},
   "source": [
    "Q3. What is PCA (Principle Component Analysis), and how is it used in dimensionality reduction? Provide an\n",
    "example to illustrate its application.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7ebb8ef-de51-4ddc-a421-d4f6c3056c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.68412563  0.31939725]\n",
      " [-2.71414169 -0.17700123]\n",
      " [-2.88899057 -0.14494943]\n",
      " [-2.74534286 -0.31829898]\n",
      " [-2.72871654  0.32675451]\n",
      " [-2.28085963  0.74133045]\n",
      " [-2.82053775 -0.08946138]\n",
      " [-2.62614497  0.16338496]\n",
      " [-2.88638273 -0.57831175]\n",
      " [-2.6727558  -0.11377425]\n",
      " [-2.50694709  0.6450689 ]\n",
      " [-2.61275523  0.01472994]\n",
      " [-2.78610927 -0.235112  ]\n",
      " [-3.22380374 -0.51139459]\n",
      " [-2.64475039  1.17876464]\n",
      " [-2.38603903  1.33806233]\n",
      " [-2.62352788  0.81067951]\n",
      " [-2.64829671  0.31184914]\n",
      " [-2.19982032  0.87283904]\n",
      " [-2.5879864   0.51356031]\n",
      " [-2.31025622  0.39134594]\n",
      " [-2.54370523  0.43299606]\n",
      " [-3.21593942  0.13346807]\n",
      " [-2.30273318  0.09870885]\n",
      " [-2.35575405 -0.03728186]\n",
      " [-2.50666891 -0.14601688]\n",
      " [-2.46882007  0.13095149]\n",
      " [-2.56231991  0.36771886]\n",
      " [-2.63953472  0.31203998]\n",
      " [-2.63198939 -0.19696122]\n",
      " [-2.58739848 -0.20431849]\n",
      " [-2.4099325   0.41092426]\n",
      " [-2.64886233  0.81336382]\n",
      " [-2.59873675  1.09314576]\n",
      " [-2.63692688 -0.12132235]\n",
      " [-2.86624165  0.06936447]\n",
      " [-2.62523805  0.59937002]\n",
      " [-2.80068412  0.26864374]\n",
      " [-2.98050204 -0.48795834]\n",
      " [-2.59000631  0.22904384]\n",
      " [-2.77010243  0.26352753]\n",
      " [-2.84936871 -0.94096057]\n",
      " [-2.99740655 -0.34192606]\n",
      " [-2.40561449  0.18887143]\n",
      " [-2.20948924  0.43666314]\n",
      " [-2.71445143 -0.2502082 ]\n",
      " [-2.53814826  0.50377114]\n",
      " [-2.83946217 -0.22794557]\n",
      " [-2.54308575  0.57941002]\n",
      " [-2.70335978  0.10770608]\n",
      " [ 1.28482569  0.68516047]\n",
      " [ 0.93248853  0.31833364]\n",
      " [ 1.46430232  0.50426282]\n",
      " [ 0.18331772 -0.82795901]\n",
      " [ 1.08810326  0.07459068]\n",
      " [ 0.64166908 -0.41824687]\n",
      " [ 1.09506066  0.28346827]\n",
      " [-0.74912267 -1.00489096]\n",
      " [ 1.04413183  0.2283619 ]\n",
      " [-0.0087454  -0.72308191]\n",
      " [-0.50784088 -1.26597119]\n",
      " [ 0.51169856 -0.10398124]\n",
      " [ 0.26497651 -0.55003646]\n",
      " [ 0.98493451 -0.12481785]\n",
      " [-0.17392537 -0.25485421]\n",
      " [ 0.92786078  0.46717949]\n",
      " [ 0.66028376 -0.35296967]\n",
      " [ 0.23610499 -0.33361077]\n",
      " [ 0.94473373 -0.54314555]\n",
      " [ 0.04522698 -0.58383438]\n",
      " [ 1.11628318 -0.08461685]\n",
      " [ 0.35788842 -0.06892503]\n",
      " [ 1.29818388 -0.32778731]\n",
      " [ 0.92172892 -0.18273779]\n",
      " [ 0.71485333  0.14905594]\n",
      " [ 0.90017437  0.32850447]\n",
      " [ 1.33202444  0.24444088]\n",
      " [ 1.55780216  0.26749545]\n",
      " [ 0.81329065 -0.1633503 ]\n",
      " [-0.30558378 -0.36826219]\n",
      " [-0.06812649 -0.70517213]\n",
      " [-0.18962247 -0.68028676]\n",
      " [ 0.13642871 -0.31403244]\n",
      " [ 1.38002644 -0.42095429]\n",
      " [ 0.58800644 -0.48428742]\n",
      " [ 0.80685831  0.19418231]\n",
      " [ 1.22069088  0.40761959]\n",
      " [ 0.81509524 -0.37203706]\n",
      " [ 0.24595768 -0.2685244 ]\n",
      " [ 0.16641322 -0.68192672]\n",
      " [ 0.46480029 -0.67071154]\n",
      " [ 0.8908152  -0.03446444]\n",
      " [ 0.23054802 -0.40438585]\n",
      " [-0.70453176 -1.01224823]\n",
      " [ 0.35698149 -0.50491009]\n",
      " [ 0.33193448 -0.21265468]\n",
      " [ 0.37621565 -0.29321893]\n",
      " [ 0.64257601  0.01773819]\n",
      " [-0.90646986 -0.75609337]\n",
      " [ 0.29900084 -0.34889781]\n",
      " [ 2.53119273 -0.00984911]\n",
      " [ 1.41523588 -0.57491635]\n",
      " [ 2.61667602  0.34390315]\n",
      " [ 1.97153105 -0.1797279 ]\n",
      " [ 2.35000592 -0.04026095]\n",
      " [ 3.39703874  0.55083667]\n",
      " [ 0.52123224 -1.19275873]\n",
      " [ 2.93258707  0.3555    ]\n",
      " [ 2.32122882 -0.2438315 ]\n",
      " [ 2.91675097  0.78279195]\n",
      " [ 1.66177415  0.24222841]\n",
      " [ 1.80340195 -0.21563762]\n",
      " [ 2.1655918   0.21627559]\n",
      " [ 1.34616358 -0.77681835]\n",
      " [ 1.58592822 -0.53964071]\n",
      " [ 1.90445637  0.11925069]\n",
      " [ 1.94968906  0.04194326]\n",
      " [ 3.48705536  1.17573933]\n",
      " [ 3.79564542  0.25732297]\n",
      " [ 1.30079171 -0.76114964]\n",
      " [ 2.42781791  0.37819601]\n",
      " [ 1.19900111 -0.60609153]\n",
      " [ 3.49992004  0.4606741 ]\n",
      " [ 1.38876613 -0.20439933]\n",
      " [ 2.2754305   0.33499061]\n",
      " [ 2.61409047  0.56090136]\n",
      " [ 1.25850816 -0.17970479]\n",
      " [ 1.29113206 -0.11666865]\n",
      " [ 2.12360872 -0.20972948]\n",
      " [ 2.38800302  0.4646398 ]\n",
      " [ 2.84167278  0.37526917]\n",
      " [ 3.23067366  1.37416509]\n",
      " [ 2.15943764 -0.21727758]\n",
      " [ 1.44416124 -0.14341341]\n",
      " [ 1.78129481 -0.49990168]\n",
      " [ 3.07649993  0.68808568]\n",
      " [ 2.14424331  0.1400642 ]\n",
      " [ 1.90509815  0.04930053]\n",
      " [ 1.16932634 -0.16499026]\n",
      " [ 2.10761114  0.37228787]\n",
      " [ 2.31415471  0.18365128]\n",
      " [ 1.9222678   0.40920347]\n",
      " [ 1.41523588 -0.57491635]\n",
      " [ 2.56301338  0.2778626 ]\n",
      " [ 2.41874618  0.3047982 ]\n",
      " [ 1.94410979  0.1875323 ]\n",
      " [ 1.52716661 -0.37531698]\n",
      " [ 1.76434572  0.07885885]\n",
      " [ 1.90094161  0.11662796]\n",
      " [ 1.39018886 -0.28266094]]\n"
     ]
    }
   ],
   "source": [
    "#PCA, or Principle Component Analysis, is a technique used in machine learning for dimensionality reduction. \n",
    "#It works by identifying the most important features, or components, of a dataset and projecting the data onto a lower-dimensional \n",
    "#space that captures as much of the original information as possible. The new dimensions, called principal components, \n",
    "#are linear combinations of the original features.\n",
    "\n",
    "#PCA is useful for reducing the number of features in a dataset while retaining as much of the relevant information as possible.\n",
    "#This can help to simplify the analysis, reduce noise, and improve the performance of machine learning algorithms.\n",
    "\n",
    "#Here's an example of how to use PCA for dimensionality reduction in Python:\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# load the iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# create a dataframe with the iris data\n",
    "df = pd.DataFrame(data=iris['data'], columns=iris['feature_names'])\n",
    "\n",
    "# initialize the PCA object\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# fit and transform the data\n",
    "df_pca = pca.fit_transform(df)\n",
    "\n",
    "# print the transformed data\n",
    "print(df_pca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75f85984-1620-4490-9175-cbbab62d8999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                  5.1               3.5                1.4               0.2\n",
       "1                  4.9               3.0                1.4               0.2\n",
       "2                  4.7               3.2                1.3               0.2\n",
       "3                  4.6               3.1                1.5               0.2\n",
       "4                  5.0               3.6                1.4               0.2\n",
       "..                 ...               ...                ...               ...\n",
       "145                6.7               3.0                5.2               2.3\n",
       "146                6.3               2.5                5.0               1.9\n",
       "147                6.5               3.0                5.2               2.0\n",
       "148                6.2               3.4                5.4               2.3\n",
       "149                5.9               3.0                5.1               1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2e057b-a026-4420-929d-f882b1f87586",
   "metadata": {},
   "outputs": [],
   "source": [
    "#So actually we reduced our data to 2d from 4d\n",
    "#so we can easily visualize and use in ml model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6015cb7-086b-4fb7-ba5e-affa2de1136b",
   "metadata": {},
   "source": [
    "Q4. What is the relationship between PCA and Feature Extraction, and how can PCA be used for Feature\n",
    "Extraction? Provide an example to illustrate this concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4e2d611-0bc0-4f82-91ab-4f26177118e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.68412563  0.31939725]\n",
      " [-2.71414169 -0.17700123]\n",
      " [-2.88899057 -0.14494943]\n",
      " [-2.74534286 -0.31829898]\n",
      " [-2.72871654  0.32675451]\n",
      " [-2.28085963  0.74133045]\n",
      " [-2.82053775 -0.08946138]\n",
      " [-2.62614497  0.16338496]\n",
      " [-2.88638273 -0.57831175]\n",
      " [-2.6727558  -0.11377425]\n",
      " [-2.50694709  0.6450689 ]\n",
      " [-2.61275523  0.01472994]\n",
      " [-2.78610927 -0.235112  ]\n",
      " [-3.22380374 -0.51139459]\n",
      " [-2.64475039  1.17876464]\n",
      " [-2.38603903  1.33806233]\n",
      " [-2.62352788  0.81067951]\n",
      " [-2.64829671  0.31184914]\n",
      " [-2.19982032  0.87283904]\n",
      " [-2.5879864   0.51356031]\n",
      " [-2.31025622  0.39134594]\n",
      " [-2.54370523  0.43299606]\n",
      " [-3.21593942  0.13346807]\n",
      " [-2.30273318  0.09870885]\n",
      " [-2.35575405 -0.03728186]\n",
      " [-2.50666891 -0.14601688]\n",
      " [-2.46882007  0.13095149]\n",
      " [-2.56231991  0.36771886]\n",
      " [-2.63953472  0.31203998]\n",
      " [-2.63198939 -0.19696122]\n",
      " [-2.58739848 -0.20431849]\n",
      " [-2.4099325   0.41092426]\n",
      " [-2.64886233  0.81336382]\n",
      " [-2.59873675  1.09314576]\n",
      " [-2.63692688 -0.12132235]\n",
      " [-2.86624165  0.06936447]\n",
      " [-2.62523805  0.59937002]\n",
      " [-2.80068412  0.26864374]\n",
      " [-2.98050204 -0.48795834]\n",
      " [-2.59000631  0.22904384]\n",
      " [-2.77010243  0.26352753]\n",
      " [-2.84936871 -0.94096057]\n",
      " [-2.99740655 -0.34192606]\n",
      " [-2.40561449  0.18887143]\n",
      " [-2.20948924  0.43666314]\n",
      " [-2.71445143 -0.2502082 ]\n",
      " [-2.53814826  0.50377114]\n",
      " [-2.83946217 -0.22794557]\n",
      " [-2.54308575  0.57941002]\n",
      " [-2.70335978  0.10770608]\n",
      " [ 1.28482569  0.68516047]\n",
      " [ 0.93248853  0.31833364]\n",
      " [ 1.46430232  0.50426282]\n",
      " [ 0.18331772 -0.82795901]\n",
      " [ 1.08810326  0.07459068]\n",
      " [ 0.64166908 -0.41824687]\n",
      " [ 1.09506066  0.28346827]\n",
      " [-0.74912267 -1.00489096]\n",
      " [ 1.04413183  0.2283619 ]\n",
      " [-0.0087454  -0.72308191]\n",
      " [-0.50784088 -1.26597119]\n",
      " [ 0.51169856 -0.10398124]\n",
      " [ 0.26497651 -0.55003646]\n",
      " [ 0.98493451 -0.12481785]\n",
      " [-0.17392537 -0.25485421]\n",
      " [ 0.92786078  0.46717949]\n",
      " [ 0.66028376 -0.35296967]\n",
      " [ 0.23610499 -0.33361077]\n",
      " [ 0.94473373 -0.54314555]\n",
      " [ 0.04522698 -0.58383438]\n",
      " [ 1.11628318 -0.08461685]\n",
      " [ 0.35788842 -0.06892503]\n",
      " [ 1.29818388 -0.32778731]\n",
      " [ 0.92172892 -0.18273779]\n",
      " [ 0.71485333  0.14905594]\n",
      " [ 0.90017437  0.32850447]\n",
      " [ 1.33202444  0.24444088]\n",
      " [ 1.55780216  0.26749545]\n",
      " [ 0.81329065 -0.1633503 ]\n",
      " [-0.30558378 -0.36826219]\n",
      " [-0.06812649 -0.70517213]\n",
      " [-0.18962247 -0.68028676]\n",
      " [ 0.13642871 -0.31403244]\n",
      " [ 1.38002644 -0.42095429]\n",
      " [ 0.58800644 -0.48428742]\n",
      " [ 0.80685831  0.19418231]\n",
      " [ 1.22069088  0.40761959]\n",
      " [ 0.81509524 -0.37203706]\n",
      " [ 0.24595768 -0.2685244 ]\n",
      " [ 0.16641322 -0.68192672]\n",
      " [ 0.46480029 -0.67071154]\n",
      " [ 0.8908152  -0.03446444]\n",
      " [ 0.23054802 -0.40438585]\n",
      " [-0.70453176 -1.01224823]\n",
      " [ 0.35698149 -0.50491009]\n",
      " [ 0.33193448 -0.21265468]\n",
      " [ 0.37621565 -0.29321893]\n",
      " [ 0.64257601  0.01773819]\n",
      " [-0.90646986 -0.75609337]\n",
      " [ 0.29900084 -0.34889781]\n",
      " [ 2.53119273 -0.00984911]\n",
      " [ 1.41523588 -0.57491635]\n",
      " [ 2.61667602  0.34390315]\n",
      " [ 1.97153105 -0.1797279 ]\n",
      " [ 2.35000592 -0.04026095]\n",
      " [ 3.39703874  0.55083667]\n",
      " [ 0.52123224 -1.19275873]\n",
      " [ 2.93258707  0.3555    ]\n",
      " [ 2.32122882 -0.2438315 ]\n",
      " [ 2.91675097  0.78279195]\n",
      " [ 1.66177415  0.24222841]\n",
      " [ 1.80340195 -0.21563762]\n",
      " [ 2.1655918   0.21627559]\n",
      " [ 1.34616358 -0.77681835]\n",
      " [ 1.58592822 -0.53964071]\n",
      " [ 1.90445637  0.11925069]\n",
      " [ 1.94968906  0.04194326]\n",
      " [ 3.48705536  1.17573933]\n",
      " [ 3.79564542  0.25732297]\n",
      " [ 1.30079171 -0.76114964]\n",
      " [ 2.42781791  0.37819601]\n",
      " [ 1.19900111 -0.60609153]\n",
      " [ 3.49992004  0.4606741 ]\n",
      " [ 1.38876613 -0.20439933]\n",
      " [ 2.2754305   0.33499061]\n",
      " [ 2.61409047  0.56090136]\n",
      " [ 1.25850816 -0.17970479]\n",
      " [ 1.29113206 -0.11666865]\n",
      " [ 2.12360872 -0.20972948]\n",
      " [ 2.38800302  0.4646398 ]\n",
      " [ 2.84167278  0.37526917]\n",
      " [ 3.23067366  1.37416509]\n",
      " [ 2.15943764 -0.21727758]\n",
      " [ 1.44416124 -0.14341341]\n",
      " [ 1.78129481 -0.49990168]\n",
      " [ 3.07649993  0.68808568]\n",
      " [ 2.14424331  0.1400642 ]\n",
      " [ 1.90509815  0.04930053]\n",
      " [ 1.16932634 -0.16499026]\n",
      " [ 2.10761114  0.37228787]\n",
      " [ 2.31415471  0.18365128]\n",
      " [ 1.9222678   0.40920347]\n",
      " [ 1.41523588 -0.57491635]\n",
      " [ 2.56301338  0.2778626 ]\n",
      " [ 2.41874618  0.3047982 ]\n",
      " [ 1.94410979  0.1875323 ]\n",
      " [ 1.52716661 -0.37531698]\n",
      " [ 1.76434572  0.07885885]\n",
      " [ 1.90094161  0.11662796]\n",
      " [ 1.39018886 -0.28266094]]\n"
     ]
    }
   ],
   "source": [
    "#PCA (Principal Component Analysis) can be used as a feature extraction technique because it extracts the most important features,\n",
    "#called principal components, from a dataset while reducing the dimensionality. In other words, PCA can be used to transform a \n",
    "#high-dimensional dataset with many features into a lower-dimensional dataset with fewer features, while retaining as much of the\n",
    "#original information as possible.\n",
    "\n",
    "#In the context of machine learning, feature extraction is the process of extracting relevant features from the original dataset \n",
    "#that can be used to train a machine learning model. Feature extraction is important because it can help to improve the performance\n",
    "#of the model by reducing the amount of noise and irrelevant information in the data.\n",
    "\n",
    "#PCA can be used for feature extraction by identifying the principal components that capture the most variance in the data. \n",
    "#These principal components can be used as the new features in a reduced-dimensional dataset.\n",
    "\n",
    "#Here's an example of how to use PCA for feature extraction in Python:\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# load the iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# create a dataframe with the iris data\n",
    "df = pd.DataFrame(data=iris['data'], columns=iris['feature_names'])\n",
    "\n",
    "# initialize the PCA object\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# fit and transform the data\n",
    "df_pca = pca.fit_transform(df)\n",
    "\n",
    "# print the transformed data\n",
    "print(df_pca)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b633ccc4-e9b8-45b5-9c9a-6e953ac82ac5",
   "metadata": {},
   "source": [
    "Q5. You are working on a project to build a recommendation system for a food delivery service. The dataset\n",
    "contains features such as price, rating, and delivery time. Explain how you would use Min-Max scaling to\n",
    "preprocess the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "218af683-f925-4c2c-82a4-14dc147a6ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In the context of building a recommendation system for a food delivery service, Min-Max scaling can be used to preprocess the\n",
    "#numerical features such as price, rating, and delivery time. Min-Max scaling is a common technique used in data preprocessing\n",
    "#to scale the values of numerical features to a fixed range, usually between 0 and 1.\n",
    "\n",
    "#The purpose of scaling the features using Min-Max scaling is to ensure that each feature contributes equally to the recommendation model,\n",
    "#regardless of their original scale or magnitude. This is important because if features are not scaled, features with a larger magnitude \n",
    "#can dominate the model, leading to biased recommendations.\n",
    "\n",
    "#To use Min-Max scaling to preprocess the data, we can follow these steps:\n",
    "\n",
    "#Import the necessary libraries for data preprocessing, such as NumPy and scikit-learn.\n",
    "\n",
    "#Load the dataset into a pandas dataframe.\n",
    "\n",
    "#Select the numerical features that need to be scaled, such as price, rating, and delivery time.\n",
    "\n",
    "#Apply Min-Max scaling to the selected features using the MinMaxScaler function from scikit-learn.\n",
    "\n",
    "#Replace the original numerical features with the scaled features in the dataframe.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94964e6b-6ae4-4842-a936-b962c7587094",
   "metadata": {},
   "source": [
    "Q6. You are working on a project to build a model to predict stock prices. The dataset contains many\n",
    "features, such as company financial data and market trends. Explain how you would use PCA to reduce the\n",
    "dimensionality of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b93d0787-a14b-4425-9165-e032a7b2f91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In the context of building a model to predict stock prices, it is common to have a large number of features such as company\n",
    "#financial data and market trends. However, having a large number of features can lead to overfitting and increased computational \n",
    "#complexity. To address these issues, dimensionality reduction techniques such as PCA (Principal Component Analysis) can be\n",
    "#used to reduce the number of features while retaining as much information as possible.\n",
    "\n",
    "#Here are the steps to use PCA to reduce the dimensionality of the dataset:\n",
    "\n",
    "#Import the necessary libraries for data preprocessing, such as NumPy and scikit-learn.\n",
    "\n",
    "#Load the dataset into a pandas dataframe.\n",
    "\n",
    "#Select the features that need to be included in the PCA analysis.\n",
    "\n",
    "#Standardize the selected features using the StandardScaler function from scikit-learn.\n",
    "\n",
    "#Initialize the PCA object with the desired number of principal components to retain.\n",
    "\n",
    "#Fit the PCA object to the standardized features using the fit_transform method.\n",
    "\n",
    "#Create a new dataframe with the reduced number of principal components."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88272b6-8137-4366-a7e2-d702ee94bc8c",
   "metadata": {},
   "source": [
    "Q7. For a dataset containing the following values: [1, 5, 10, 15, 20], perform Min-Max scaling to transform the\n",
    "values to a range of -1 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01b8720a-92f7-4e61-93f7-de84d1ae1117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.        ]\n",
      " [0.21052632]\n",
      " [0.47368421]\n",
      " [0.73684211]\n",
      " [1.        ]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# create a sample dataset with two features\n",
    "data = {\"values\":[1,5,10,15,20]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# fit and transform the data\n",
    "df_scaled = scaler.fit_transform(df)\n",
    "\n",
    "# print the scaled data\n",
    "print(df_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6a8b76-d9c2-4e33-ac8d-f5cee140448a",
   "metadata": {},
   "source": [
    "Q8. For a dataset containing the following features: [height, weight, age, gender, blood pressure], perform\n",
    "Feature Extraction using PCA. How many principal components would you choose to retain, and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f26a6d4a-9755-4722-a9c5-79d65729030e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before applying PCA, we need to standardize the data because PCA is sensitive to the scale of the features. \n",
    "#This means that features with larger scales (e.g., weight) will have a greater impact on the principal components \n",
    "#than features with smaller scales (e.g., age).\n",
    "\n",
    "#Once we standardize the data, we can apply PCA to extract the principal components. The number of principal components we choose to \n",
    "#retain depends on the amount of variance we want to preserve in the data.\n",
    "\n",
    "#One common approach is to choose the number of principal components that explain a certain percentage of the total variance. \n",
    "#For example, we may choose to retain enough principal components to explain 90% of the total variance.\n",
    "\n",
    "#Alternatively, we can use the elbow method to choose the number of principal components. \n",
    "#The elbow method involves plotting the explained variance ratio for each principal component and choosing the number of components\n",
    "#where the explained variance starts to level off.\n",
    "\n",
    "#Without additional information about the dataset, it is difficult to determine the appropriate number of principal components to retain.\n",
    "#However, as a general rule of thumb, we may choose to retain enough principal components to explain at least 80-90% of the total variance.\n",
    "\n",
    "#Note that the choice of the number of principal components to retain also depends on the specific application and the desired trade-off\n",
    "#between reducing the dimensionality of the data and preserving information.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31927e2-4ba8-4f3a-b314-4710083c31a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
