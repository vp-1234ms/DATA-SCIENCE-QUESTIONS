{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d914c93-5f5d-4eb0-90e0-c2fcf9615162",
   "metadata": {},
   "source": [
    "Q1. A company conducted a survey of its employees and found that 70% of the employees use the\n",
    "company's health insurance plan, while 40% of the employees who use the plan are smokers. What is the\n",
    "probability that an employee is a smoker given that he/she uses the health insurance plan?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d35b4c1-59ed-4ce0-8000-224b8c0d287c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can use Bayes' theorem to calculate the probability that an employee is a smoker given that he/she uses the health insurance plan:\n",
    "\n",
    "#P(smoker | uses insurance) = P(uses insurance | smoker) * P(smoker) / P(uses insurance)\n",
    "\n",
    "#We are given that 70% of the employees use the company's health insurance plan, so P(uses insurance) = 0.7. We are also given that 40% of the \n",
    "#employees who use the plan are smokers, so P(uses insurance | smoker) = 0.4. Finally, we know that the overall percentage of smokers among all\n",
    "#employees is not provided. For the sake of this example, let's assume it is 20%, i.e. P(smoker) = 0.2.\n",
    "\n",
    "#Now we can substitute these values into the formula:\n",
    "\n",
    "#P(smoker | uses insurance) = 0.4 * 0.2 / 0.7 = 0.114\n",
    "\n",
    "#Therefore, the probability that an employee is a smoker given that he/she uses the health insurance plan is 0.114 or approximately 11.4%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfb611c-9434-47e8-b766-526919fb3b25",
   "metadata": {},
   "source": [
    "Q2. What is the difference between Bernoulli Naive Bayes and Multinomial Naive Bayes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f837fb64-38fc-438b-839f-e76a5c4f040a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bernoulli Naive Bayes and Multinomial Naive Bayes are both variations of Naive Bayes algorithm that are commonly used for text classification.\n",
    "#The key difference between them lies in the way they represent the input features.\n",
    "\n",
    "#Bernoulli Naive Bayes assumes that the input features are binary (i.e., either present or absent). For example, in text classification, the presence\n",
    "#or absence of each word in a document can be considered a binary feature. Therefore, in Bernoulli Naive Bayes, each feature is represented by a\n",
    "#binary value indicating whether it is present or absent. The probability of a feature given a class is calculated as the number of times the \n",
    "#feature appears in documents of that class divided by the total number of documents of that class.\n",
    "\n",
    "#On the other hand, Multinomial Naive Bayes assumes that the input features represent count data (i.e., how many times a particular feature occurs).\n",
    "#In text classification, this means that each feature is represented by the count of the number of times it appears in a document. The probability \n",
    "#of a feature given a class is calculated as the sum of the counts of that feature in all documents of that class, divided by the total number of\n",
    "#words in those documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf42d08b-be28-46f8-a26c-37e2c7dfdcbb",
   "metadata": {},
   "source": [
    "Q3. How does Bernoulli Naive Bayes handle missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ec9f869-d69a-41c1-bea8-7392d0ee5b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In Bernoulli Naive Bayes, missing values are typically handled by ignoring them during the model training phase. When the algorithm encounters a \n",
    "#missing value during model training, it simply skips that feature and continues with the next feature. This is because Bernoulli Naive Bayes assumes\n",
    "#that the input features are binary (i.e., either present or absent), and if a feature is missing, it is not considered present or absent, and \n",
    "#therefore cannot be used for classification.\n",
    "\n",
    "#During model prediction, if a test instance contains a missing value, the algorithm treats that feature as absent (i.e., it assumes that the feature\n",
    "#is not present in the instance). This is based on the assumption that if a feature is not present in a document, it is equivalent to the feature \n",
    "#being missing or unknown.\n",
    "\n",
    "#In some cases, it may be possible to use imputation techniques to fill in missing values before training the Bernoulli Naive Bayes model.\n",
    "#For example, one could use a simple imputation method such as replacing missing values with the mode (most common value) of that feature \n",
    "#across the training data. However, this approach should be used with caution, as it may introduce bias into the model if the imputed values are\n",
    "#not representative of the true values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ecd2ea-d4e1-4d27-8318-37cb92248a9a",
   "metadata": {},
   "source": [
    "Q4. Can Gaussian Naive Bayes be used for multi-class classification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b960eb7b-8de5-40c8-9ea2-2b61ccb861a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Yes, Gaussian Naive Bayes can be used for multi-class classification problems. In multi-class classification, there are more than two classes, \n",
    "#and the goal is to predict the class of a new instance based on its input features.\n",
    "\n",
    "#In Gaussian Naive Bayes, the algorithm assumes that the input features are continuous and follows a Gaussian (normal) distribution. To use\n",
    "#Gaussian Naive Bayes for multi-class classification, the algorithm calculates the probability of each class for a new instance, based on its \n",
    "#input features, using Bayes' theorem. The class with the highest probability is then assigned as the predicted class.\n",
    "\n",
    "#The algorithm calculates the probability of a new instance belonging to a particular class using the class-specific mean and variance of each \n",
    "#feature. In the case of multi-class classification, the mean and variance of each feature are calculated for each class separately.\n",
    "\n",
    "#In summary, Gaussian Naive Bayes can be used for multi-class classification by calculating the probability of each class for a new instance and\n",
    "#selecting the class with the highest probability as the predicted class. The algorithm uses the class-specific mean and variance of each feature\n",
    "#to calculate these probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6d818f-dad0-48f0-856d-dbdbe455bbfd",
   "metadata": {},
   "source": [
    "Q5. Assignment:\n",
    "Data preparation:\n",
    "Download the \"Spambase Data Set\" from the UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/\n",
    "datasets/Spambase). This dataset contains email messages, where the goal is to predict whether a message\n",
    "is spam or not based on several input features.\n",
    "Implementation:\n",
    "Implement Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes classifiers using the\n",
    "scikit-learn library in Python. Use 10-fold cross-validation to evaluate the performance of each classifier on the\n",
    "dataset. You should use the default hyperparameters for each classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e41524a-436f-4b27-a804-703850564357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5c0548-9d0f-47fc-8070-6b5898b02436",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
