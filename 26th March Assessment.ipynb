{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9c5eb2d-89af-4381-b700-6c6a6e51bf68",
   "metadata": {},
   "source": [
    "Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an\n",
    "example of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94a2ffd7-de15-4b54-b1f8-b6abfb473f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple linear regression is a statistical method used to model the relationship between a dependent variable and a single independent variable.\n",
    "#It assumes that there is a linear relationship between the two variables, which can be represented by a straight line on a scatter plot. \n",
    "#For example, one may want to investigate the relationship between a person's age and their weight.\n",
    "\n",
    "#Multiple linear regression, on the other hand, is used to model the relationship between a dependent variable and two or more independent variables.\n",
    "#It assumes that there is a linear relationship between the dependent variable and each independent variable, as well as an additive relationship\n",
    "#between the independent variables themselves. For example, one may want to investigate the relationship between a person's salary and their age,\n",
    "#education level, and years of experience.\n",
    "\n",
    "#An example of simple linear regression would be:\n",
    "\n",
    "#Suppose we want to study the relationship between the number of hours a student studies per week and their exam scores. We collect data on \n",
    "#50 students and plot their hours of study against their exam scores on a scatter plot. We find that there is a positive linear relationship\n",
    "#between the two variables, indicating that as the number of hours studied increases, the exam scores also tend to increase. \n",
    "#Suppose we want to study the relationship between a car's fuel efficiency and its engine size, horsepower, and weight.\n",
    "#We collect data on 100 cars and plot their fuel efficiency against each of these three independent variables on a scatter plot.\n",
    "#We find that each of these independent variables has a significant linear relationship with fuel efficiency, and there may also be interactions \n",
    "#between the variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64014a89-bfef-4c78-b4fc-d4731fa68fa1",
   "metadata": {},
   "source": [
    "Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in\n",
    "a given dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "679f9d91-c832-425a-a81c-be76f4da1292",
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are several assumptions that underlie linear regression models. These assumptions are important because if they are violated, \n",
    "#the resulting regression estimates may be biased or unreliable. Here are some of the key assumptions of linear regression:\n",
    "\n",
    "#Linearity: The relationship between the dependent variable and each independent variable is linear. This means that the regression equation should\n",
    "#be a straight line.\n",
    "\n",
    "#Independence: The observations are independent of each other. This means that there is no systematic relationship between the residuals and \n",
    "#any of the independent variables.\n",
    "\n",
    "#Homoscedasticity: The variance of the residuals is constant across all levels of the independent variable(s). This means that the scatter\n",
    "#of the residuals should be approximately equal at all levels of the independent variable(s).\n",
    "\n",
    "#Normality: The residuals are normally distributed. This means that the distribution of the residuals should be approximately bell-shaped.\n",
    "\n",
    "#No multicollinearity: There is no perfect correlation between any two independent variables.\n",
    "\n",
    "#No influential outliers: There are no extreme values of the independent variable(s) that have a disproportionate impact on the regression line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fc40bb-fd9d-47b1-9a50-d6874a93324b",
   "metadata": {},
   "source": [
    "Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example using\n",
    "a real-world scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "306c2eda-87b8-4b8b-b02a-5f543fb6b387",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In a linear regression model, the slope and intercept coefficients provide information about the relationship between the dependent variable and\n",
    "#the independent variable(s).\n",
    "\n",
    "#The slope coefficient (often denoted as \"b\") represents the amount by which the dependent variable changes for a one-unit increase in the\n",
    "#independent variable, holding all other variables constant. In other words, it represents the rate of change in the dependent variable for \n",
    "#each unit change in the independent variable. A positive slope coefficient indicates a positive relationship between the variables, \n",
    "#while a negative slope coefficient indicates a negative relationship.\n",
    "\n",
    "#The intercept coefficient (often denoted as \"a\") represents the predicted value of the dependent variable when all independent variables are zero.\n",
    "#In other words, it represents the value of the dependent variable when the independent variable has no effect.\n",
    "\n",
    "#Here is an example using a real-world scenario:\n",
    "\n",
    "#Suppose we want to investigate the relationship between a person's height and weight. We collect data on 100 people and fit a linear regression\n",
    "#model with weight as the dependent variable and height as the independent variable. The resulting regression equation is:\n",
    "\n",
    "#weight = 10 + 5(height) + error term\n",
    "\n",
    "#In this equation, the intercept coefficient (a) is 10, which means that a person who has a height of zero (which is not possible in reality) is \n",
    "#predicted to have a weight of 10. The slope coefficient (b) is 5, which means that for every one-unit increase in height, the predicted weight \n",
    "#increases by 5 pounds, holding all other variables constant. Therefore, a person who is one inch taller than another person is predicted to weigh\n",
    "#5 pounds more than the other person, on average."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d86f5fd-5dbd-4d33-93a8-a366b50084f0",
   "metadata": {},
   "source": [
    "Q4. Explain the concept of gradient descent. How is it used in machine learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ed6abdf-21db-4d72-91fe-21300cdab243",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient descent is an optimization algorithm used in machine learning to minimize the cost function of a model by adjusting the model's parameters\n",
    "#iteratively. It is a first-order optimization algorithm that finds the minimum of a cost function by taking steps proportional to the negative \n",
    "#of the gradient of the function.\n",
    "\n",
    "#The gradient is a vector that points in the direction of the steepest ascent of the function. By taking the negative of the gradient, \n",
    "#we can move in the direction of the steepest descent of the function, which leads us towards the minimum.\n",
    "\n",
    "#In the context of machine learning, the cost function is a measure of how well the model fits the data. The goal of gradient descent\n",
    "#is to adjust the model's parameters in such a way that the cost function is minimized, which means that the model is the best possible fit for\n",
    "#the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11c62c3-be57-4bb5-9be1-7970226ae8b4",
   "metadata": {},
   "source": [
    "Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0425114d-07c7-4002-aa43-3e3a11fdec5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiple linear regression is a statistical model that examines the linear relationship between a dependent variable and two or more independent\n",
    "#variables. It is an extension of the simple linear regression model, which examines the relationship between a dependent variable and a single \n",
    "#independent variable.\n",
    "#Number of independent variables: Simple linear regression has one independent variable, whereas multiple linear regression has two or \n",
    "#more independent variables.\n",
    "\n",
    "#Interpretation of coefficients: In simple linear regression, the slope coefficient represents the change in the dependent variable associated\n",
    "#with a one-unit increase in the independent variable. In multiple linear regression, each slope coefficient represents the change in the dependent\n",
    "#variable associated with a one-unit increase in the corresponding independent variable, holding all other variables constant.\n",
    "\n",
    "#Model complexity: Multiple linear regression is a more complex model than simple linear regression because it includes two or more independent \n",
    "#variables. As a result, it may be more difficult to interpret and may require more data to estimate accurately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cd47c8-fb81-42b7-acab-767b05c14e3c",
   "metadata": {},
   "source": [
    "Q6. Explain the concept of multicollinearity in multiple linear regression. How can you detect and\n",
    "address this issue?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea9ecd13-f331-42de-a0b2-db4718dae0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multicollinearity is a phenomenon that occurs when two or more independent variables in a multiple linear regression model are highly correlated \n",
    "#with each other. This can lead to several issues in the analysis, including unstable and unreliable estimates of the regression coefficients, \n",
    "#difficulty in interpreting the coefficients, and reduced predictive accuracy of the model.\n",
    "\n",
    "#Multicollinearity can be detected by examining the correlation matrix of the independent variables. A high correlation between two or more variables \n",
    "#may indicate the presence of multicollinearity. Another way to detect multicollinearity is to calculate the variance inflation factor (VIF) for each \n",
    "#independent variable. VIF measures the degree to which the variance of the estimated regression coefficient is increased due to multicollinearity.\n",
    "#A VIF value of 1 indicates no multicollinearity, while values greater than 1 indicate increasing levels of multicollinearity.\n",
    "\n",
    "#To address the issue of multicollinearity, several methods can be used, including:\n",
    "\n",
    "#Dropping one or more highly correlated variables: If two or more variables are highly correlated, one of them can be dropped from the model to \n",
    "#reduce the level of multicollinearity.\n",
    "\n",
    "#Combining highly correlated variables: Instead of dropping one of the highly correlated variables, they can be combined into a single variable,\n",
    "#such as a weighted average or principal component.\n",
    "\n",
    "#Regularization techniques: Regularization techniques, such as ridge regression and lasso regression, can be used to shrink the regression \n",
    "#coefficients towards zero, which can help reduce the impact of multicollinearity on the model.\n",
    "\n",
    "#Collecting more data: Collecting more data can help reduce the impact of multicollinearity by increasing the sample size and reducing \n",
    "#the correlation between the independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb3fa1f-8bac-4b33-9920-83582e454586",
   "metadata": {},
   "source": [
    "Q7. Describe the polynomial regression model. How is it different from linear regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63ced506-924d-4e9d-9510-51832bc82d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Polynomial regression is a form of regression analysis in which the relationship between the independent variable and dependent variable\n",
    "#is modeled as an nth degree polynomial function. In other words, polynomial regression models assume that the relationship between the \n",
    "#independent variable and dependent variable is not linear, but can be better described by a curved line or surface.\n",
    "\n",
    "#Polynomial regression models are different from linear regression models in several ways:\n",
    "\n",
    "#Functional form: The functional form of a polynomial regression model is a polynomial equation of degree n, while the functional form of a \n",
    "#linear regression model is a straight line.\n",
    "\n",
    "#Degree of complexity: Polynomial regression models are generally more complex than linear regression models, as they allow for a wider range \n",
    "#of possible relationships between the independent and dependent variables.\n",
    "\n",
    "#Flexibility: Polynomial regression models are more flexible than linear regression models in that they can capture nonlinear relationships \n",
    "#between the independent and dependent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f67fbd-51c9-4ef4-93ee-08f46bcef6b0",
   "metadata": {},
   "source": [
    "Q8. What are the advantages and disadvantages of polynomial regression compared to linear\n",
    "regression? In what situations would you prefer to use polynomial regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f00b6cf5-72b6-4f55-967c-0e729d1a1229",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Advantages of polynomial regression over linear regression:\n",
    "\n",
    "#Flexibility: Polynomial regression models are more flexible than linear regression models as they can capture nonlinear relationships between\n",
    "#the independent and dependent variables.\n",
    "\n",
    "#Better fit: In cases where the relationship between the independent and dependent variables is nonlinear, polynomial regression models\n",
    "#can provide a better fit to the data compared to linear regression models.\n",
    "\n",
    "#Higher accuracy: In situations where the underlying relationship between the variables is a curve, polynomial regression models can provide \n",
    "#higher accuracy compared to linear regression models.\n",
    "\n",
    "#Disadvantages of polynomial regression compared to linear regression:\n",
    "\n",
    "#Complexity: Polynomial regression models are more complex than linear regression models, as they require fitting higher order polynomial equations \n",
    "#to the data.\n",
    "\n",
    "#Overfitting: Polynomial regression models are prone to overfitting, where the model fits the training data too closely and fails to generalize\n",
    "#well to new data.\n",
    "\n",
    "#Interpretability: Polynomial regression models can be less interpretable compared to linear regression models, especially when the degree of\n",
    "#the polynomial is high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d910885-60ba-4b50-893e-9f2d13aee545",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
